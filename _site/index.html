<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <title>WebShop</title>
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <link rel="icon" type="image/x-icon" href="/assets/static/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#e77500">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=">

    <!-- MathJax -->
    <script
      type="text/javascript"
      async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"
    >
    </script>

    <!-- Twitter cards -->
    <meta name="twitter:site"    content="@princeton_nlp">
    <meta name="twitter:title"   content="WebShop">
    <meta name="twitter:card"    content="summary">
    <meta name="twitter:image"   content="">
    <meta name="twitter:description" content="Towards Scalable Real-World Web Interaction with Grounded Language Agents">
  </head>
  <body>
    <header class="page-header" role="banner">
      <h1 class="project-name">WebShop</h1>
      
      <h2 class="project-tagline">Towards Scalable Real-World Web Interaction with Grounded Language Agents</h2>
      
      
      <a class="project-link" href=https://ysymyth.github.io/>Shunyu Yao<sup>
      *
      1</sup></a>
      
      &emsp;
      
      
      <a class="project-link" href=https://howard50b.github.io/>Howard Chen<sup>
      *
      1</sup></a>
      
      &emsp;
      
      
      <a class="project-link" href=https://john-b-yang.github.io/>John Yang<sup>
      
      1</sup></a>
      
      &emsp;
      
      
      <a class="project-link" href=https://www.cs.princeton.edu/~karthikn/>Karthik Narasimhan<sup>
      
      1</sup></a>
      
      
      <div style="margin-top: 1rem">
        <a class="project-link" href="https://princeton-nlp.github.io/"><sup>1</sup>Princeton University</a>
      </div>
      <p>*indicates equal contribution</p>
      
      <a href="https://github.com/princeton-nlp/WebShop" class="btn"><b>üíª&emsp;Repo (Env. + Baseline)</b></a>
      
      
      <a href="https://arxiv.org/abs/2207.01206" class="btn"><b>üìù&emsp;Paper</b></a>
      
    </header>

    <main id="content" class="main-content" role="main">
      <div style="text-align:center;">
  <b>A scalable, simulated web environment with real-world data for developing grounded language agents</b>
</div>

<p><img src="assets/static/diagram.gif" /></p>

<h2 id="abstract">Abstract</h2>

<p>Existing benchmarks for grounding language in interactive environments either lack real-world linguistic elements, or prove difficult to scale up due to substantial human involvement in the collection of data or feedback signals. To bridge this gap, we develop WebShop ‚Äì a simulated e-commerce website environment with 1.18 million real-world products and 12,087 crowd-sourced text instructions. Given a text instruction specifying a product requirement, an agent needs to navigate multiple types of webpages and issue diverse actions to find, customize, and purchase an item. WebShop provides several challenges for language grounding including understanding compositional instructions, query (re-)formulation, comprehending and acting on noisy text in webpages, and performing strategic exploration. We collect over 1,600 human demonstrations for the task, and train and evaluate a diverse range of agents using reinforcement learning, imitation learning, and pre-trained image and language models. Our best model achieves a task success rate of 29%, which outperforms rule-based heuristics (9.6%) but is far lower than human expert performance (59%). We also analyze agent and human trajectories and ablate various model components to provide insights for developing future agents with stronger language understanding and decision making abilities. Finally, we show that agents trained on WebShop exhibit non-trivial <em>sim-to-real</em> transfer when evaluated on <a href="https://www.amazon.com/">amazon.com</a>, indicating the potential value of WebShop in developing practical web-based agents that can operate in the wild.</p>

<h2 id="webshop-environment">WebShop Environment</h2>

<video controls="" width="100%">
  <source src="assets/static/demo.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

<p>Try out the WebShop environment for yourself at the live site <a href="http://3.83.245.205:3000/pnlp">here</a>!</p>

<p>The WebShop environment features a variety of <b>states</b> and a number of <b>actions</b> to transition from one state to the next. A state <code class="language-plaintext highlighter-rouge">s</code> represents one of four types of webpages:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">search</code> page that contains a search bar</li>
  <li><code class="language-plaintext highlighter-rouge">results</code> page that lists a set of products returned by a search engine</li>
  <li><code class="language-plaintext highlighter-rouge">item</code> page that describes a product</li>
  <li><code class="language-plaintext highlighter-rouge">item-detail</code> page that shows further information about the product</li>
</ul>

<p>At each state, an agent has two choices of actions: to either <b>search</b> a text query (e.g. <code class="language-plaintext highlighter-rouge">search[Red shoes]</code>) or <b>choose</b> a text button (e.g. <code class="language-plaintext highlighter-rouge">choose[Size 9]</code>). The following table lists the full set of available actions and the state transitions they correspond to.</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Argument</th>
      <th>State ‚Üí Next State</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>search</td>
      <td>[Query]</td>
      <td>Search ‚Üí Results</td>
    </tr>
    <tr>
      <td>choose</td>
      <td>Back to Search</td>
      <td>* ‚Üí Search</td>
    </tr>
    <tr>
      <td>choose</td>
      <td>Prev/Next Page</td>
      <td>Results ‚Üí Results</td>
    </tr>
    <tr>
      <td>choose</td>
      <td>[Product Title]</td>
      <td>Results ‚Üí Item</td>
    </tr>
    <tr>
      <td>choose</td>
      <td>[Option]</td>
      <td>Item ‚Üí Item</td>
    </tr>
    <tr>
      <td>choose</td>
      <td>Desc/Overview</td>
      <td>Item-Detail ‚Üí Item</td>
    </tr>
    <tr>
      <td>choose</td>
      <td>Buy</td>
      <td>Item ‚Üí Episode End</td>
    </tr>
  </tbody>
</table>

<p>Within this environment, an agent is given a human-provided text <b>instruction</b> and asked to purchase a product that matches the specifications. <b>Rewards</b> are automatically computed using a combination of programmatic matching functions that consider the attributes, type, options and price of the chosen product</p>

<p>In the WebShop environment setting, an agent is presented with a variety of challenges for language grounding, including understanding compositional instructions, query (re-)formulation, comprehending and acting on noisy text in webpages, and performing strategic exploration.</p>

<h2 id="demo">Demo</h2>

<h3 id="interactive-web-app">Interactive Web App</h3>

<iframe src="https://hf.space/gradioiframe/webshop/amazon_shop/+" width="100%" height="900"></iframe>

<h3 id="trajectories">Trajectories</h3>

<p>The below slides show the step-by-step actions of trajectories generated from different agents and entities performing the task of searching for a product based on a goal instruction.</p>

<p><strong>Goal Instruction</strong>: I‚Äôm looking for a quick-release replacement fitness strap band; it should match my chic teal fitbit, and price lower than 40.00 dollars</p>

<p>These first four slideshows showcase trajectories by an MTurk worker, Rule Based Heuristic Imitation Learning Agent, and Imitation Learning + Reinforcement Learning Agent searching for a product on WebShop given the same goal instruction.</p>

<div style="text-align:center;">
    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRv8w_xsn8Y2dIH9bteRaR74gGv0TDdCYBa460JNefCa5pmbrwxc5FFUCzk2dx-ElVsy99dMcyme2Vh/embed?start=false&amp;loop=false&amp;delayms=10000" frameborder="0" width="49%" height="300" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQa-LV0_ElycuIjva2TLwj3LKdZfhbEgGX0rzZbt1a6Jjkl9t-pcakCJMGRiJV_wnUrfptvCN_x_cm0/embed?start=false&amp;loop=false&amp;delayms=10000" frameborder="0" width="49%" height="300" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
</div>
<div style="text-align:center;">
    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vR2xraC_z1pX4J7Ajb00MmqFBj5HwXu88sLz7a8bp6rNTydoWJEWc1qUsfFLLgtUa1boM0Y3c8OhSN2/embed?start=false&amp;loop=false&amp;delayms=10000" frameborder="0" width="49%" height="300" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTZ8tS8jgniUgVw2MGLxmih5fj-8GQdxKNOM3gYpPlLY91Tj6bSM39qpqfdoqQI00I8QhyAae_7P1eM/embed?start=false&amp;loop=false&amp;delayms=10000" frameborder="0" width="49%" height="300" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
</div>

<p><em>Sim-to-real Transfer</em>: This last slideshow shows a trajectory generated by an Imitation Learning agent searching on the www.amazon.com website, achieved via sim-to-real transfer logic.</p>

<div style="text-align:center;">
    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRmGmWmt5PInGy4qSG7JZg9LcDAHULrH8sGY2QIXyD55KsikNxMZ5nhlPHYrB_nOa8g8DtIIqJolfjD/embed?start=false&amp;loop=false&amp;delayms=10000" frameborder="0" width="49%" height="300" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
</div>

<h2 id="citation">Citation</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{yao2022webshop,
  bibtex_show = {true},
  title = {WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents},
  author = {Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  booktitle = {ArXiv},
  year = {preprint},
  html = {https://arxiv.org/abs/2207.01206},
  tag = {NLP}
}
</code></pre></div></div>


      <h2 id="authors">Authors</h2>
      <div class="container">
      
        <figure>
          
          <a href=https://ysymyth.github.io/><img src=https://ysymyth.github.io/images/self.jpeg height="110" alt=Shunyu Yao class="profphoto" id="firstprofphoto"></a>
          
          <figcaption><a href=https://ysymyth.github.io/>Shunyu Yao</a></figcaption>
        </figure>
      
        <figure>
          
          <a href=https://howard50b.github.io/><img src=https://www.cs.princeton.edu/~danqic/images/members/howard_chen.jpg height="110" alt=Howard Chen class="profphoto"></a>
          
          <figcaption><a href=https://howard50b.github.io/>Howard Chen</a></figcaption>
        </figure>
      
        <figure>
          
          <a href=https://john-b-yang.github.io/><img src=https://john-b-yang.github.io/static/profpic.jpg height="110" alt=John Yang class="profphoto"></a>
          
          <figcaption><a href=https://john-b-yang.github.io/>John Yang</a></figcaption>
        </figure>
      
        <figure>
          
          <a href=https://www.cs.princeton.edu/~karthikn/><img src=https://princeton-nlp.github.io/assets/images/people/karthik-photo.jpg height="110" alt=Karthik Narasimhan class="profphoto"></a>
          
          <figcaption><a href=https://www.cs.princeton.edu/~karthikn/>Karthik Narasimhan</a></figcaption>
        </figure>
      
      </div>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/webshop-pnlp/webshop-pnlp.github.io">WebShop</a>
          is maintained by <a href="https://github.com/princeton-nlp">princeton-nlp</a>.
        </span>
      </footer>
    </main>
  </body>
</html>
